{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSLZVZSPw_pQ"
   },
   "outputs": [],
   "source": [
    "# Python Modules\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "from skimage.metrics import adapted_rand_error, variation_of_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZgslhMsa2TB"
   },
   "outputs": [],
   "source": [
    "# constants and paths to our data\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 256, 256\n",
    "NUM_CHANNELS = 3\n",
    "NEW_IMAGE_SHAPE = (256, 256, 3)\n",
    "NEW_MASK_SHAPE = (256, 256)\n",
    "\n",
    "train_path = ''\n",
    "valid_path = ''\n",
    "test_path = ''\n",
    "checkpoint_path = ''\n",
    "model_save_path = ''\n",
    "\n",
    "channel_wise_mean = (0.3711, 0.4098, 0.4071)\n",
    "channel_wise_stdev = (0.2742, 0.2638, 0.2709)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJuQOhVsmSs7"
   },
   "outputs": [],
   "source": [
    "# set up tensorboard\n",
    "\n",
    "# Install latest Tensorflow build\n",
    "import tensorflow as tf\n",
    "from tensorflow import summary\n",
    "%load_ext tensorboard\n",
    "\n",
    "current_time = str(datetime.datetime.now().timestamp())\n",
    "train_log_dir = 'logs/tensorboard/train/' + current_time\n",
    "test_log_dir = 'logs/tensorboard/test/' + current_time\n",
    "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OR5SUbOvBUn7"
   },
   "outputs": [],
   "source": [
    "## Early Stopping\n",
    "## https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            print(\"saving checkpoint\")\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        now = datetime.now()\n",
    "        date_time = now.strftime(\"%H_%M_%S\")\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model, checkpoint_path + '/' + date_time + '_checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10vagEL0YBk7"
   },
   "outputs": [],
   "source": [
    "# define custom dataset class which is interpretable by DataLoader\n",
    "\n",
    "#augmentation: https://debuggercafe.com/image-augmentation-using-pytorch-and-albumentations/\n",
    "# and https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/\n",
    "\n",
    "class CustomDataset():\n",
    "    def __init__(self, image_paths, target_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.image_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                                    transforms.Normalize(channel_wise_mean, channel_wise_stdev)])\n",
    "        self.mask_transforms = transforms.ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = np.array(plt.imread(self.image_paths[index])) / 255.0\n",
    "        mask = np.array(plt.imread(self.target_paths[index])) / 255.0\n",
    "        \n",
    "        # horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            image = np.fliplr(image)\n",
    "            mask = np.fliplr(mask)\n",
    "        \n",
    "        # vertical flip\n",
    "        if random.random() > 0.5:\n",
    "            image = np.flipud(image)\n",
    "            mask = np.flipud(mask)\n",
    "\n",
    "        # 90 degree rotation\n",
    "        if random.random() > 0.5:\n",
    "            image = np.rot90(image)\n",
    "            mask = np.rot90(mask)\n",
    "\n",
    "        # add noise\n",
    "        sigma = random.random()\n",
    "        if random.random() < 0.25:\n",
    "            image = random_noise(image, var=(sigma)**2)\n",
    "\n",
    "        # gaussian blur\n",
    "        if random.random() < 0.25:\n",
    "            image = gaussian(image, sigma=1, multichannel=True)\n",
    "\n",
    "        t_image = self.image_transforms(image.copy())\n",
    "        t_mask = self.mask_transforms(mask.copy())\n",
    "        t_mask = t_mask.squeeze()\n",
    "        return t_image, t_mask\n",
    "\n",
    "    def __len__(self):  # return count of sample we have\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jBnAvk7HXYZo",
    "outputId": "17b01d27-fd6a-49d5-a97c-50435fccfe7e"
   },
   "outputs": [],
   "source": [
    "# generate train, test, and validation loaders\n",
    "\n",
    "def generate_loader(path, batch_size):\n",
    "  folder_sat = glob.glob(path + \"/sat/*.tif\")\n",
    "  folder_map = glob.glob(path + \"/map/*.tif\")\n",
    "  len_data = len(folder_sat)\n",
    "  print(len_data)\n",
    "  sat_paths = folder_sat\n",
    "  map_paths = folder_map\n",
    "  dataset = CustomDataset(sat_paths, map_paths)\n",
    "  loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "  return loader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "valid_loader = generate_loader(valid_path, BATCH_SIZE)\n",
    "test_loader = generate_loader(valid_path, BATCH_SIZE)\n",
    "train_loader = generate_loader(train_path, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44rMq4bgwVpJ"
   },
   "outputs": [],
   "source": [
    "# UNet Implementation by\n",
    "# https://github.com/jvanvugt/pytorch-unet/blob/master/unet.py\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=3,\n",
    "        n_classes=1,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kk__gkCwVr2"
   },
   "outputs": [],
   "source": [
    "# training loop for UNet model\n",
    "\n",
    "def train():\n",
    "    # training \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNet(in_channels=3, n_classes=2, padding=True).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    dataloader = train_loader\n",
    "    val_dataloader = valid_loader\n",
    "    \n",
    "    epochs = 1000\n",
    "    patience = 5\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "        train_losses = []\n",
    "        N = 0\n",
    "        model.train()\n",
    "        for X, y in tqdm(dataloader):\n",
    "            X = X.to(device)  # [N, 3, H, W]\n",
    "            y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "            n = X.shape[0]\n",
    "            N += n # increment counter of training examples\n",
    "            prediction = model(X) # [N, 1, H, W]\n",
    "            loss = F.cross_entropy(prediction, y.long()) * n # multiply by batchsize since cross_entropy takes the average\n",
    "            train_losses.append(loss)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        avg_training_loss = np.sum(np.array(train_losses)) / N \n",
    "\n",
    "        ## compute validation error\n",
    "        val_losses = []\n",
    "        N = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in tqdm(val_dataloader):\n",
    "                X = X.to(device)  # [N, 3, H, W]\n",
    "                y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "                n = X.shape[0]\n",
    "                N += n\n",
    "                prediction = model(X) # [N, 1, H, W]\n",
    "                loss = F.cross_entropy(prediction, y.long()) * n\n",
    "                val_losses.append(loss)\n",
    "        \n",
    "        avg_val_loss = np.sum(np.array(val_losses)) / N\n",
    "\n",
    "        toc = time.perf_counter()\n",
    "        print(f\"Epoch {epoch}: Train Loss = {avg_training_loss}, Validation Loss = {avg_val_loss}, and took {toc - tic:0.4f} seconds\")\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "          tf.summary.scalar('training loss', avg_training_loss.item(), step=epoch)\n",
    "          tf.summary.scalar('validation loss', avg_val_loss.item(), step=epoch)\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "        \n",
    "    # save model\n",
    "    torch.save(model, model_save_path)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3b4e7f764ded4dfdad3a7f4699fb2760",
      "3d0a7846b61f4421b99255f7cd450030",
      "a7743056ca684552afe20951fef508fb",
      "51180394d1404a69a6533c6009934bd3",
      "70aa5916566541adb7602fc154ddda5b",
      "3a615157d97544499b5566647a2e4ff0",
      "fa9fb26bc40d4520827ae69f38291411",
      "f8733fd025eb42efba54b39506d8b172"
     ]
    },
    "colab_type": "code",
    "id": "nHjn5ya28Mzo",
    "outputId": "e10067f9-f387-4de4-e5bd-c695ec832891"
   },
   "outputs": [],
   "source": [
    "# test model\n",
    "# At test time, restart the runtime because cuda runs out of memory\n",
    "model = torch.load(checkpoint_path + '/10_44_17_checkpoint.pt')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_losses = []\n",
    "rand_error = []\n",
    "pixel_error = []\n",
    "N = 0\n",
    "THRESHOLD = -0.5\n",
    "counter = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(test_loader):\n",
    "        tic = time.perf_counter()\n",
    "\n",
    "        X = X.to(device)  # [N, 3, H, W]\n",
    "        y = y.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        n = X.shape[0]\n",
    "        N += n\n",
    "        prediction = model(X) # [N, 1, H, W]\n",
    "\n",
    "        # compute loss\n",
    "        loss = F.cross_entropy(prediction, y.long()) * n\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        # Generate Masks\n",
    "        predicted_mask_0 = prediction[5].permute(1,2,0)[:,:,0].cpu().numpy()\n",
    "        predicted_mask_0[predicted_mask_0>THRESHOLD] = 1\n",
    "        predicted_mask_0[predicted_mask_0<=THRESHOLD] = 0\n",
    "\n",
    "        predicted_mask_1 = prediction[5].permute(1,2,0)[:,:,1].cpu().numpy()\n",
    "        predicted_mask_1[predicted_mask_1>THRESHOLD] = 1\n",
    "        predicted_mask_1[predicted_mask_1<=THRESHOLD] = 0\n",
    "\n",
    "        # Plot Predictions\n",
    "        fig = plt.figure(counter)\n",
    "        fig.subplots_adjust(hspace=0.4)\n",
    "        ax1 = fig.add_subplot(2,2,1)\n",
    "        ax1.set_title('Original Image')\n",
    "        ax1.imshow(X[5].permute(1,2,0).cpu().numpy() + channel_wise_mean)\n",
    "        ax2 = fig.add_subplot(2,2,2)\n",
    "        ax2.set_title('Ground Truth')\n",
    "        ax2.imshow(y[5].cpu().numpy(), cmap='gray')\n",
    "        ax3 = fig.add_subplot(2,2,3)\n",
    "        ax3.set_title('Predicted Channel 0')\n",
    "        ax3.imshow(predicted_mask_0, cmap='gray')  \n",
    "        ax4 = fig.add_subplot(2,2,4)\n",
    "        ax4.set_title('Predicted Channel 1')\n",
    "        ax4.imshow(predicted_mask_1, cmap='gray')  \n",
    "        counter += 1\n",
    "\n",
    "        # compute random error\n",
    "        prediction = prediction.permute(0,2,3,1)[:,:,:,1].cpu().numpy()\n",
    "        prediction[prediction>THRESHOLD] = 1\n",
    "        prediction[prediction<=THRESHOLD] = 0\n",
    "        prediction = prediction.astype(int) + 1\n",
    "        y = y.cpu().numpy().astype(int) + 1\n",
    "        r_error = 0\n",
    "        for i in range(n):\n",
    "            error, precision, recall = adapted_rand_error(y[i], prediction[i])\n",
    "            r_error += error\n",
    "        rand_error.append(r_error)\n",
    "\n",
    "        # compute pixel-wise error\n",
    "        prediction -= 1\n",
    "        y -= 1\n",
    "        p_error = np.sqrt(np.sum((y - prediction)**2))\n",
    "        pixel_error.append(p_error)\n",
    "   \n",
    "    avg_test_loss = np.sum(np.array(test_losses)) / N\n",
    "    avg_rand_error = np.sum(np.array(rand_error)) / N\n",
    "    avg_pixel_error = np.sum(np.array(pixel_error)) / N\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Test Loss = {avg_test_loss}, Rand Error = {avg_rand_error}, Pixel Error = {avg_pixel_error}, and took {toc - tic:0.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "UNetBaseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "24421bb2dec94af19972017cd7f8304e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e612f8e2ee1e41d79e825c3097ea489c",
      "placeholder": "​",
      "style": "IPY_MODEL_a3ca22ed943b43f6af81785ee5ccf961",
      "value": " 0/39 [00:27&lt;?, ?it/s]"
     }
    },
    "3a615157d97544499b5566647a2e4ff0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b4e7f764ded4dfdad3a7f4699fb2760": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7743056ca684552afe20951fef508fb",
       "IPY_MODEL_51180394d1404a69a6533c6009934bd3"
      ],
      "layout": "IPY_MODEL_3d0a7846b61f4421b99255f7cd450030"
     }
    },
    "3d0a7846b61f4421b99255f7cd450030": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b333cf11450456cac7cb8563748d5bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0431c6aea274c389a391ecd2b495b22",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_baf5e99f9aa147cb97336a4a015dae0a",
      "value": 0
     }
    },
    "51180394d1404a69a6533c6009934bd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8733fd025eb42efba54b39506d8b172",
      "placeholder": "​",
      "style": "IPY_MODEL_fa9fb26bc40d4520827ae69f38291411",
      "value": " 39/39 [00:18&lt;00:00,  2.09it/s]"
     }
    },
    "6dc0385b494b4fbaad2a77d3c0088cbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b333cf11450456cac7cb8563748d5bc",
       "IPY_MODEL_24421bb2dec94af19972017cd7f8304e"
      ],
      "layout": "IPY_MODEL_f89c0ee4fdfb429692b4b929b35efad2"
     }
    },
    "70aa5916566541adb7602fc154ddda5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a3ca22ed943b43f6af81785ee5ccf961": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7743056ca684552afe20951fef508fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a615157d97544499b5566647a2e4ff0",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70aa5916566541adb7602fc154ddda5b",
      "value": 39
     }
    },
    "baf5e99f9aa147cb97336a4a015dae0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d0431c6aea274c389a391ecd2b495b22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e612f8e2ee1e41d79e825c3097ea489c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8733fd025eb42efba54b39506d8b172": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f89c0ee4fdfb429692b4b929b35efad2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa9fb26bc40d4520827ae69f38291411": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
